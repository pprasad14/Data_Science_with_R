Titanic
margin.table(Titanic,1)
margin.table(Titanic, 4)
str(Titanic)
margin.table(Titanic)
barplot(margin.table(Titanic))
barplot(margin.table(Titanic,4))
barplot(margin.table(Titanic,1))
margin.table(Titanic, 4)  #survived is 4th attribute
barplot(margin.table(Titanic,4))
data("airquality")
?airquality
str(airquality)
t = airquality$Temp
hist(t)
range(t)
hist(t,
main = "Max daily Temperature",
xlab = "Temp in F",
xlim = c(50,100),
col = "green",
freq = T)
range(t)
hist(t,
main = "Max daily Temperature",
xlab = "Temp in F",
xlim = c(50,100),    # to set x limits
col = "green",
freq = F)
g = hist(t)
g
hist(t,
main = "Max daily Temperature",
xlab = "Temp in F",
xlim = c(50,100),    # to set x limits
col = "green",
freq = T)   # freq = F shows density
hist(t, breaks = 4, main = "break = 4")
hist(t, breaks = 15, main = "break = 4")
hist(t, breaks = 15, main = "break = 15")
hist(t,
main = "Max daily Temperature",
xlab = "Temp in F",
xlim = c(50,100),    # to set x limits
col = "green",
breaks = c(55,60,65,70,75,85,100))
temp = c(22,24,25,23,22,24,25)
barplot(temp)
barplot(temp,
main = "max temp in a week",
xlab = "degress in celcius",
ylab = "day",
names.arg = c('sun','mon','tue','wed','thu','fri','sat'),
col = "cyan")
barplot(table(age)) # correct plot
table(age)  # need a plot to show this information ie frequencies
barplot(table(age),
main = "Age count",
xlab = "age",
ylab = "count",
col = "blue",
border = "red", # the color to be used for the border of the bars.
density = 15)   # no. of line per inch for bar components
x = c(25,37,60,11)
pie(x)
labels = c("A","B","C","D")
pie(x,labels)
f = sample(1:30)
pie(f)
pie(x,labels, col = c("red",'blue','green','yellow'))
boxplot(airquality$Ozone)
boxplot(airquality$Ozone,
main = "mean ozone in parts per billion",
xlab = "Parts per billion",
ylab = "Ozone",
col = "pink",
border = "black",
horizontal = F)
boxplot(airquality$Ozone,
main = "mean ozone in parts per billion",
xlab = "Parts per billion",
ylab = "Ozone",
col = "pink",
border = "black",
horizontal =T)
boxplot(airquality$Ozone,
main = "mean ozone in parts per billion",
xlab = "Parts per billion",
ylab = "Ozone",
col = "pink",
border = "black",
horizontal =T) #for horizontal boxes
boxplot(airquality$Ozone,
main = "mean ozone in parts per billion",
xlab = "Parts per billion",
ylab = "Ozone",
col = "pink",
border = "black",
horizontal = F,
notch = T)
boxplot(airquality$Ozone,
main = "mean ozone in parts per billion",
xlab = "Parts per billion",
ylab = "Ozone",
col = "pink",
border = "black",
horizontal = T,
notch = T)
boxplot(Temp ~ Month,
data = airquality,
main = "differen boxplot for each month",
xlab = "month no.",
ylab = "degree F",
color = "yellow",
border = "red")
boxplot(Temp ~ Month,
data = airquality,
main = "differen boxplot for each month",
xlab = "month no.",
ylab = "degree F",
col = "yellow",
border = "red")
View(airquality)
sal = c(35,43,55,67,43,78,30,44,42,55,77)
barplot(sal)
meansal = mean(sal)
abline(h = meansal)
avg(sal)
average(sal)
mean(sal)
medsal = median(sal)
abline(h = medsal)
abline(h = medsal,col = 'red')
dev = sd(sal)
abline(h = meansal + dev, col= "blue")
abline(h = meansal - dev, col= "yellow")
chest = c('gold','silver','gem','gold','gem','gem','silver')
types = factor(chest)
weight = c(200,300,200,500,450,350,250)
prices = c(9000,5000,6000,6000,3000,2500,7000)
plot(weight, prices)
plot(weight, prices, pch = as.integer(types))
legend("topright", c("gem","gold","silver"), pch = 1:3)
legend("topright", c("gem","gold","silver"))
legend("topright", c("gem","gold","silver"), pch = 1:3)
# train and test for Boston Dataset
dataset("Boston
")
# train and test for Boston Dataset
library(MASS)
dataset(Boston)
set.seed(123)
split_boston = sample.split(Boston$medv, SplitRatio = 0.8)
library(caTools)
split_boston = sample.split(Boston$medv, SplitRatio = 0.8)
split_boston = sample.split(dataset$medv, SplitRatio = 0.8)
split_boston = sample.split(Boston$medv, SplitRatio = 0.8)
xbar = 9900 #sample mean
xbar = 9900 #sample mean
mu0 = 10000 #hypothesized value
sigma = 120   # Pop SD
n = 30
z = (xbar - mu0)/(sigma / sqrt(n))
z # test statistic
alpha = 0.05
z.alpha = qnorm(1-alpha)
z = (xbar - mu0)/(sigma / sqrt(n))
alpha = 0.025
z.alpha = qnorm(1-alpha)
z.alpha
alpha = 0.05
z.alpha = qnorm(1-alpha)
alpha = 0.05
z.alpha = qnorm(1-alpha)
-z.alpha  # critical value of z at lower tail
pval = pnorm(z)
pval
pval = pnorm(z)
qnorm(.9938)
qnorm(.9394)
pval = pnorm(z)
pval
pval < alpha
xbar = 2.1 #sample mean
mu0 = 2 #hypothesized value
sigma = 0.25  # Pop SD
n = 35
z = (xbar - mu0)/(sigma / sqrt(n))
z  # test statistic
alpha = 0.05
z.alpha = qnorm(1-alpha)
z.alpha
pval = pnorm(z, lower.tail = F)
pval
pval = pnorm(z, lower.tail = T)
pval
pval = pnorm(z, lower.tail = F)
pval
xbar = 14.6 #sample mean
mu0 = 15.4 #hypothesized value
sigma = 2.5   # Pop SD
n = 35
z = (xbar - mu0)/(sigma / sqrt(n))
xbar = 14.6 #sample mean
mu0 = 15.4 #hypothesized value
sigma = 2.5   # Pop SD
n = 35
z = (xbar - mu0)/(sigma / sqrt(n))
alpha = 0.05
z.alpha = qnorm(1-alpha/2)  # alpha/2 since it is two tailed
z = (xbar - mu0)/(sigma / sqrt(n))
alpha = 0.05
z.alpha = qnorm(1-alpha/2)  # alpha/2 since it is two tailed
xbar = 9900 #sample mean
mu0 = 10000 #hypothesized value
s = 125   # Sample SD
n = 30
t = (xbar - mu0)/(s / sqrt(n))
#Step 2: find critical value
alpha = 0.05
t.alpha = qt(1 - alpha, df = n-1)
pval = pt(t, df = n-1)
pval
dataset = read.csv("bank.csv")
dataset = read.csv("bank.csv")
dataset = read.csv("bank.csv")
setwd("C:/Users/Prem Prasad/Desktop/Rstudio weekday(Divyang)/R_Data_Science_Part_2")
dataset = read.csv("bank.csv")
strsplit(dataset[-1,], ";")
strsplit(dataset, ";")
strsplit(dataset, "")
View(dataset)
as.data.frame(dataset)
strsplit(as.data.frame(dataset))
strsplit(as.data.frame(dataset),";")
L
dataset = read.csv("bank.csv", header = T)
View(dataset)
dataset = read.csv("bank.csv",sep = ";" header = T)
dataset = read.csv("bank.csv",sep = ";", header = T)
View(dataset)
data_set = read.csv("bank.csv",sep = ";", header = T)
dataset = read.csv("bank.csv",sep = ";", header = T)
library(readr)
diabetes <- read_csv("diabetes.csv")
View(diabetes)
library(caTools)
set.seed(123)
split = sample.split(dataset$y, .8)
table(split)
training_set = subset(dataset, split ==T)
test_set = subset(dataset, split == F)
summary(training_set)
colSums(is.na(dataset))
training_set[-17] = scale(training_set[-17])  # to scale all columns but 3rd column in training_set
summary(training_set)
colSums(is.na(dataset))
classifier = glm(y ~ ., data = training_set,
family = "binomial")
summary(classifier)
prob_pred = predict(classifier, newdata = test_set[-17],
type = "response")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
#Confusion Matrix
cm = table(Actual = test_set[,9], Predicted = y_pred)
#Confusion Matrix
cm = table(Actual = test_set[,17], Predicted = y_pred)
cm
library(MLmetrics)
ConfusionMatrix(test_set[,17], y_pred) # **
Accuracy(test_set[,17], y_pred)
library(caret)
confusionMatrix(test_set[,17], y_pred)
prob_pred = predict(classifier, newdata = test_set,
type = "response")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
#Confusion Matrix
cm = table(Actual = test_set[,17], Predicted = y_pred)
cm
ConfusionMatrix(test_set[,17], y_pred) # **
Accuracy(test_set[,17], y_pred)
table(y_pred)
#Confusion Matrix
cm = table(Actual = test_set[,17], Predicted = y_pred)
cm
library(caret)
confusionMatrix(test_set[,3], y_pred)
ConfusionMatrix(test_set[,17], y_pred) # **
Accuracy(test_set[,3], y_pred)
dataset = read.csv("Social_Network_Ads.csv")
View(dataset)
dataset = dataset[3:5]
dataset$Purchased = factor(dataset$Purchased, levels = c(0,1))
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, 0.75)
training_set = subset(dataset, split == T)
test_set = subset(dataset, split == F)
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
install.packages("rpart")
install.packages("rpart")
library(rpart)
set.seed(123)
classifier = rpart(formula = Purchased ~ ., data = training_set)
y_pred = predict(classifier, newdata = test_set[-3]) # gives probabilities
y_pred = predict(classifier, newdata = test_set[-3],
type = "class")
head(y_pred)
library(caret)
confusionMatrix(test_set[,3], y_pred)
library(ElemStatLearn)
plot(classifier, margin = 0.1)
text(classifier)
library(rpart.plot)
rpart.plot(classifier, type = 3, digits = 3, fallen.leaves = T,
cex = 0.6)
data = read.table("German.txt")
dataset = read.table("German.txt")
colnames(data) = c('checking_acc_status','duration','credit_history','purpose',
'amount','savings_or_bonds','emp_duration','install_rate',
'personal_info','others','residence_duration','property',
'age','install_plans','housing','no_of_credits','job_info',
'no_of_people_liable','telephone','foreign_worker','credit_worthy')
View(dataset)
colnames(dataset) = c('checking_acc_status','duration','credit_history','purpose',
'amount','savings_or_bonds','emp_duration','install_rate',
'personal_info','others','residence_duration','property',
'age','install_plans','housing','no_of_credits','job_info',
'no_of_people_liable','telephone','foreign_worker','credit_worthy')
dataset = read.table("German.txt")
colnames(dataset) = c('checking_acc_status','duration','credit_history','purpose',
'amount','savings_or_bonds','emp_duration','install_rate',
'personal_info','others','residence_duration','property',
'age','install_plans','housing','no_of_credits','job_info',
'no_of_people_liable','telephone','foreign_worker','credit_worthy')
dataset = dataset[c(2,5,8,11,13,16,18)]
dataset = read.table("German.txt")
colnames(dataset) = c('checking_acc_status','duration','credit_history','purpose',
'amount','savings_or_bonds','emp_duration','install_rate',
'personal_info','others','residence_duration','property',
'age','install_plans','housing','no_of_credits','job_info',
'no_of_people_liable','telephone','foreign_worker','credit_worthy')
View(dataset)
dataset = dataset[c(2,5,8,11,13,16,18,21)]
dataset$credit_worthy = as.factor(dataset$credit_worthy)
library(caTools)
set.seed(123)
split = sample.split(dataset$credit_worthy, 0.75)
training_set = subset(dataset, split == T)
test_set = subset(dataset, split == F)
training_set[-8] = scale(training_set[-8])
test_set[-8] = scale(test_set[-8])
library(rpart)
set.seed(123)
classifier = rpart(formula = credit_worthy ~ ., data = training_set)
y_pred = predict(classifier, newdata = test_set[-8]) # gives probabilities
y_pred = predict(classifier, newdata = test_set[-8],
type = "class")
head(y_pred)
library(caret)
confusionMatrix(test_set[,3], y_pred)
confusionMatrix(test_set[,8], y_pred)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('X', 'Y')
y_grid = predict(classifier, type = 'class', newdata = grid_set)
plot(set[, -8],
main = 'Decision Tree (training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
plot(set[, -8],
main = 'Decision Tree (training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
plot(set[, -8],
main = 'Decision Tree (training set)',
xlab = 'X', ylab = Y,
xlim = range(X1), ylim = range(X2))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, type = 'class', newdata = grid_set)
plot(set[, -3],
main = 'Decision Tree (training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
plot(set[, -8],
main = 'Decision Tree (training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
y_grid = predict(classifier, type = 'class', newdata = grid_set)
y_grid = predict(classifier, type = 'class', newdata = grid_set)
plot(classifier, margin = 0.1)
text(classifier)
library(rpart.plot)
rpart.plot(classifier, type = 3, digits = 3, fallen.leaves = T,
cex = 0.6)
dataset = read.table("German.txt")
colnames(dataset) = c('checking_acc_status','duration','credit_history','purpose',
'amount','savings_or_bonds','emp_duration','install_rate',
'personal_info','others','residence_duration','property',
'age','install_plans','housing','no_of_credits','job_info',
'no_of_people_liable','telephone','foreign_worker','credit_worthy')
dataset = dataset[,c('duration','amount','install_rate','residence_duration','age',
'no_of_credits','no_of_people_liable','credit_worthy')]
dataset$credit_worthy = as.factor(dataset$credit_worthy)
library(caTools) #to work with train and test
set.seed(123)
split = sample.split(dataset$credit_worthy, 0.8)
table(split)
training_set = subset(dataset, split ==T)
test_set = subset(dataset, split == F)
training_set[-8] = scale(training_set[-8])
test_set[-8] = scale(test_set[-8])
classifier = glm(credit_worthy ~ ., data = training_set,
family = "binomial")
summary(classifier)
prob_pred = predict(classifier, newdata = test_set[-8],
type = "response")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
table(y_pred)
#Confusion Matrix
cm = table(Actual = test_set[,8], Predicted = y_pred)
cm
library(MLmetrics)
ConfusionMatrix(test_set[,8], y_pred) # **
Accuracy(test_set[,8], y_pred)
dataset = read.csv("bank.csv",sep = ";", header = T)
library(caTools)
set.seed(123)
split = sample.split(dataset$y, .8)
table(split)
training_set = subset(dataset, split ==T)
test_set = subset(dataset, split == F)
classifier = glm(y ~ ., data = training_set,
family = "binomial")
summary(classifier)
dataset = read.csv("bank.csv",sep = ";", header = T)
View(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$y, .8)
table(split)
training_set = subset(dataset, split ==T)
test_set = subset(dataset, split == F)
summary(dataset)
table(dataset$education)
dataset[dataset$education == "unknown"] = "secondary"
dataset$education == "unknown"
dataset[dataset$education == "unknown"] = "secondary"
dataset[dataset$education == "unknown",dataset$education] = "secondary"
table(dataset$education)
levels(dataset$education)[levels(dataset$education)== "unknown"]= "secondary"
table(dataset$education)
table(dataset$contact)
levels(dataset$contact)[levels(dataset$contact)== "unknown"]= "cellular"
table(dataset$poutcome)
classifier = glm(y ~ ., data = training_set,
family = "binomial")
summary(classifier)
prob_pred = predict(classifier, newdata = test_set,
type = "response")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
#Confusion Matrix
cm = table(Actual = test_set[,17], Predicted = y_pred)
cm
library(MLmetrics)
ConfusionMatrix(test_set[,17], y_pred) # **
Accuracy(test_set[,17], y_pred)
table(y_pred)
dataset$y = factor(dataset$y, levels = c("no","yes"), labels = c(0,1))
table(dataset$y)
library(caTools)
set.seed(123)
split = sample.split(dataset$y, .8)
table(split)
training_set = subset(dataset, split ==T)
test_set = subset(dataset, split == F)
summary(dataset)
table(dataset$education)
levels(dataset$education)[levels(dataset$education)== "unknown"]= "secondary"
table(dataset$education)
table(dataset$contact)
levels(dataset$contact)[levels(dataset$contact)== "unknown"]= "cellular"
table(dataset$education)
classifier = glm(y ~ ., data = training_set,
family = "binomial")
summary(classifier)
prob_pred = predict(classifier, newdata = test_set,
type = "response")
y_pred = ifelse(prob_pred > 0.5, 1, 0)
#Confusion Matrix
cm = table(Actual = test_set[,17], Predicted = y_pred)
cm
library(MLmetrics)
ConfusionMatrix(test_set[,17], y_pred) # **
Accuracy(test_set[,17], y_pred)
prob_pred = predict(classifier, newdata = test_set, type = "response")
y_pred2 = ifelse(prob_pred > 0.5 , 1, 0)
ConfusionMatrix(test_set$y, y_pred2)
dataset = read.csv("bank.csv")
View(dataset)
dataset = read.csv("bank.csv",sep = ";", header = T)
